# Data-exploration-and-enrichment-for-supervised-classification
The Hepatocellular Carcinoma Dataset
In this project, the goal is to address a real data science use case from data cleaning and feature assessment to visual inspection and communication of results, using the Hepatocellular Carcinoma (HCC) dataset. The HCC dataset was collected at the Coimbra Hospital and University Center (CHUC) in Portugal and contains real clinical data of patients diagnosed with HCC. The main goal of this project is to develop a machine learning pipeline capable of determining the survivability of patients at 1 year after diagnosis (e.g., “lives” or “dies”). To address this project, students should focus on each step of a standard data science pipeline and explore suitable solutions to develop an efficient machine learning solution:
● Data Exploration: An initial exploratory data analysis should be carried out including examining feature types, number of features/records, class distribution, values per attribute, etc., and highlighting feature inconsistencies such as missing values, outliers, underrepresented concepts, irrelevant features, etc. The analysis can and should be supported with visualization techniques.
● Data Preprocessing: This refers to feature pre-processing (e.g., imputation of missing values, data transformation, data scaling, etc.) and feature engineering (e.g., building new features or removing redundant features) and other tasks considered relevant.
● Data Modeling (Supervised Learning): Supervised learning includes the identification of the target concept, definition of the training and test sets, selection and parameterization of the learning algorithms to employ, and evaluation of the learning process (in particular on the test set). Decision Trees and KNN (e.g., using Scikit-learn) should be used to build classification models. Other classifiers are optional and considered as “extra elements”.
● Data Evaluation: Classification results should be compared across different evaluation metrics (performance during learning, confusion matrix, ROC/AUC, precision, recall, accuracy) using a standard train/test split. Results should be compared using tables and plots (e.g., using Seaborn or Matplotlib libraries). Other partitioning methods are considered “extra elements”.
● Interpretation of Results: This involves extracting meaningful insights from the obtained results: explain the behavior of the models, drawing conclusions about the effectiveness of the chosen algorithms and preprocessing techniques, providing recommendations for future analysis, investigating discrepancies of unexpected findings, etc.
